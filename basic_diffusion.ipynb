{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparams\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "## Data Prep\n",
    "DATA_DIM = 28 * 28\n",
    "\n",
    "dataset = CIFAR10(\n",
    "    root=\"data/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=Compose([ToTensor(), Normalize(0.5, 0.5)])\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE)\n",
    "for (X, y) in dataloader:\n",
    "    writer.add_image(\"dataformats=z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model construction\n",
    "\n",
    "class DenoiserNet(nn.Module):\n",
    "    def __init__(self, sigma_data):\n",
    "        super().__init__()\n",
    "        self.sigma_data = sigma_data\n",
    "        self.net = nn.Sequential(nn.Linear(29, 28)#TODO actually construct the denoising model...\n",
    "            \n",
    "        )\n",
    "        \n",
    "    def forward(self, noisy_image, noise_level, class_label=None, augment_labels=None):\n",
    "        \"\"\"\n",
    "        \n",
    "        Returns noise to subtract from scaled_noisy_image at a given noise_level to obtain a clean image\n",
    "        \n",
    "        scaled_noisy_image: an image scaled from \n",
    "        \n",
    "        \"\"\"\n",
    "        sigma = noise_level\n",
    "        sigma_data = self.sigma_data\n",
    "        \n",
    "        c_in = 1 / torch.sqrt(sigma_data**2 + sigma **2)\n",
    "        c_out = sigma * sigma_data / torch.sqrt(sigma**2 + sigma_data**2)\n",
    "        c_skip = sigma_data**2 / (sigma**2 + sigma_data**2)\n",
    "        c_noise = torch.log(sigma) / 4      # noise label warp\n",
    "        \n",
    "        net_input = torch.concat(c_in * noisy_image, c_noise)\n",
    "        \n",
    "        return c_skip * noisy_image + \\\n",
    "                   c_out  * self.net(net_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## forward generation\n",
    "NUM_STEPS = 100\n",
    "sigma_max = 80\n",
    "sigma_min = 0.002\n",
    "rho = 7\n",
    "LATENT_DIM = 100\n",
    "S_churn = 0 # apparently best for this method? idk if depends on VE/VP?\n",
    "S_min = 0\n",
    "S_noise = 1\n",
    "S_max = torch.inf\n",
    "class_labels = None\n",
    "\n",
    "\n",
    "step_indices = torch.arange(0, NUM_STEPS)\n",
    "\n",
    "timesteps = (sigma_max ** (1/rho) + (step_indices / (NUM_STEPS - 1)) * (sigma_min ** (1/rho) - sigma_max ** (1/rho))) ** rho\n",
    "\n",
    "def heun_sampling(net: DenoiserNet):\n",
    "    \"\"\"\n",
    "    \n",
    "    Returns a generated sample via reverse diffusion using 2nd order Heun solver\n",
    "    \n",
    "    net: trained denoiser that returns noise to subtract from a dirty image\n",
    "    \n",
    "    \"\"\"\n",
    "    # sample from gaussian\n",
    "    # set up timesteps\n",
    "    # per time step -> get to next one \n",
    "    \n",
    "    initial_noise = torch.randn(LATENT_DIM)\n",
    "    \n",
    "    img_next = initial_noise # loop initialization\n",
    "    \n",
    "    for i, t_curr, t_next in enumerate(zip(timesteps[:-1], timesteps[1:])):\n",
    "        img_curr = img_next\n",
    "        \n",
    "        # increase noise temporarily\n",
    "        gamma = min(S_churn / NUM_STEPS, torch.sqrt(2) - 1) if S_min <= t_curr <= S_max else 0\n",
    "        t_hat = net.round_sigma(t_curr + gamma * t_curr)\n",
    "        img_hat = img_curr + (t_hat ** 2 - t_curr ** 2).sqrt() * S_noise * torch.randn_like(img_curr)\n",
    "        \n",
    "        # Euler step\n",
    "        denoised = net(img_hat, t_hat, class_labels).to(torch.float64)\n",
    "        d_cur = (img_hat - denoised) / t_hat\n",
    "        img_next = img_curr + (t_next - t_hat) * d_cur\n",
    "        \n",
    "        # 2nd order correction\n",
    "        if i < NUM_STEPS - 1:\n",
    "            denoised = net(img_next, t_next, class_labels).to(torch.float64)\n",
    "            d_prime = (img_next - denoised) / t_next\n",
    "            img_next = img_hat + (t_next - t_hat) * (0.5 * d_cur + 0.5 * d_prime)\n",
    "\n",
    "    return img_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loss set up\n",
    "P_mean = -1.2       # average noise level (logarithmic)\n",
    "P_std = 1.2     # spread of random noise levels\n",
    "\n",
    "class EDMLoss(nn.Module):\n",
    "    def __init__(self, P_mean=P_mean, P_std=P_std, sigma_data=0.5):\n",
    "        super().__init__()\n",
    "        self.P_mean = P_mean\n",
    "        self.P_std = P_std\n",
    "        self.sigma_data = sigma_data\n",
    "    \n",
    "    def forward(self, net, images, labels=None, augment_pipe=None):\n",
    "        rnd_normal = torch.randn([images.shape[0], 1, 1, 1], device=images.device) # sample from random shape of device per image\n",
    "        sigma = (rnd_normal * self.P_std + self.P_mean).exp() # scale sampled noise levels\n",
    "        weight = (sigma ** 2 + self.sigma_data ** 2) / (sigma * self.sigma_data) ** 2\n",
    "        y, augment_labels = augment_pipe(images) if augment_pipe is not None else (images, None)\n",
    "        n = torch.randn_like(y) * sigma\n",
    "        D_yn = net(y + n, sigma, labels, augment_labels=augment_labels)\n",
    "        loss = weight * (D_yn - y).square().sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training loop\n",
    "P_mean = -1.2       # average noise level (logarithmic)\n",
    "P_std = 1.2     # spread of random noise levels\n",
    "\n",
    "net = DenoiserNet(P_std)\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "loss_fn = EDMLoss()\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "train = True\n",
    "count = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for (X, y) in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(net, X)\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "        loss.backwards()\n",
    "        \n",
    "writer.flush()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
