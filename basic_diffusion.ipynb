{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparams\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Data Prep\u001b[39;00m\n\u001b[1;32m      2\u001b[0m DATA_DIM \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m28\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m28\u001b[39m\n\u001b[0;32m----> 4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mMNIST\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCompose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE)\n",
      "File \u001b[0;32m/playpen-storage/vishravi/miniconda/envs/diffusion/lib/python3.11/site-packages/torchvision/datasets/mnist.py:103\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_data()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "## Data Prep\n",
    "DATA_DIM = 28 * 28\n",
    "\n",
    "dataset = MNIST(\n",
    "    root=\"path\",\n",
    "    train=True,\n",
    "    transform=Compose([ToTensor(), Normalize(0.5, 0.5)])\n",
    ")\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model construction\n",
    "\n",
    "class DenoiserNet(nn.Module):\n",
    "    def __init__(self, sigma_data):\n",
    "        super().__init__()\n",
    "        self.sigma_data = sigma_data\n",
    "        self.net = nn.Sequential([ #TODO actually construct the denoising model...\n",
    "            \n",
    "        ])\n",
    "        \n",
    "    def forward(self, noisy_image, noise_level, class_label=None):\n",
    "        \"\"\"\n",
    "        \n",
    "        Returns noise to subtract from scaled_noisy_image at a given noise_level to obtain a clean image\n",
    "        \n",
    "        scaled_noisy_image: an image scaled from \n",
    "        \n",
    "        \"\"\"\n",
    "        sigma = noise_level\n",
    "        sigma_data = self.sigma_data\n",
    "        \n",
    "        c_in = 1 / torch.sqrt(sigma_data**2)\n",
    "        c_out = sigma * sigma_data / torch.sqrt(sigma**2 + sigma_data**2)\n",
    "        c_skip = sigma_data**2 / (sigma**2 + sigma_data**2)\n",
    "        c_noise = torch.log(sigma) / 4      # noise label warp\n",
    "        \n",
    "        return c_skip * noisy_image + \\\n",
    "                   c_out  * self.net(c_in * noisy_image, c_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## forward generation\n",
    "NUM_STEPS = 100\n",
    "sigma_max = 80\n",
    "sigma_min = 0.002\n",
    "rho = 7\n",
    "LATENT_DIM = 100\n",
    "S_churn = 0 # apparently best for this method? idk if depends on VE/VP?\n",
    "S_min = 0\n",
    "S_noise = 1\n",
    "S_max = torch.inf\n",
    "class_labels = None\n",
    "\n",
    "\n",
    "step_indices = torch.arange(0, NUM_STEPS)\n",
    "\n",
    "timesteps = (sigma_max ** (1/rho) + (step_indices / (NUM_STEPS - 1)) * (sigma_min ** (1/rho) - sigma_max ** (1/rho))) ** rho\n",
    "\n",
    "def heun_sampling(net: DenoiserNet):\n",
    "    \"\"\"\n",
    "    \n",
    "    Returns a generated sample via reverse diffusion using 2nd order Heun solver\n",
    "    \n",
    "    net: trained denoiser that returns noise to subtract from a dirty image\n",
    "    \n",
    "    \"\"\"\n",
    "    # sample from gaussian\n",
    "    # set up timesteps\n",
    "    # per time step -> get to next one \n",
    "    \n",
    "    initial_noise = torch.randn(LATENT_DIM)\n",
    "    \n",
    "    img_next = initial_noise # loop initialization\n",
    "    \n",
    "    for i, t_curr, t_next in enumerate(zip(timesteps[:-1], timesteps[1:])):\n",
    "        img_curr = img_next\n",
    "        \n",
    "        # increase noise temporarily\n",
    "        gamma = min(S_churn / NUM_STEPS, torch.sqrt(2) - 1) if S_min <= t_curr <= S_max else 0\n",
    "        t_hat = net.round_sigma(t_curr + gamma * t_curr)\n",
    "        img_hat = img_curr + (t_hat ** 2 - t_curr ** 2).sqrt() * S_noise * torch.randn_like(img_curr)\n",
    "        \n",
    "        # Euler step\n",
    "        denoised = net(img_hat, t_hat, class_labels).to(torch.float64)\n",
    "        d_cur = (img_hat - denoised) / t_hat\n",
    "        img_next = img_curr + (t_next - t_hat) * d_cur\n",
    "        \n",
    "        # 2nd order correction\n",
    "        if i < NUM_STEPS - 1:\n",
    "            denoised = net(img_next, t_next, class_labels).to(torch.float64)\n",
    "            d_prime = (img_next - denoised) / t_next\n",
    "            img_next = img_hat + (t_next - t_hat) * (0.5 * d_cur + 0.5 * d_prime)\n",
    "\n",
    "    return img_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## loss set up\n",
    "P_mean = -1.2       # average noise level (logarithmic)\n",
    "P_std = 1.2     # spread of random noise levels\n",
    "\n",
    "class EDMLoss(nn.Module):\n",
    "    def __init__(self, P_mean=P_mean, P_std=P_std, sigma_data=0.5):\n",
    "        self.P_mean = P_mean\n",
    "        self.P_std = P_std\n",
    "        self.sigma_data = sigma_data\n",
    "    \n",
    "    def forward(self, net, images, labels=None, augment_pipe=None):\n",
    "        rnd_normal = torch.randn([images.shape[0], 1, 1, 1], device=images.device) # sample from random shape of device per image\n",
    "        sigma = (rnd_normal * self.P_std + self.P_mean).exp() # scale sampled noise levels\n",
    "        weight = (sigma ** 2 + self.sigma_data ** 2) / (sigma * self.sigma_data) ** 2\n",
    "        y, augment_labels = augment_pipe(images) if augment_pipe is not None else (images, None)\n",
    "        n = torch.randn_like(y) * sigma\n",
    "        D_yn = net(y + n, sigma, labels, augment_labels=augment_labels)\n",
    "        loss = weight * ((D_yn - y) ** 2)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training loop\n",
    "P_mean = -1.2       # average noise level (logarithmic)\n",
    "P_std = 1.2     # spread of random noise levels\n",
    "\n",
    "optimizer = torch.optim.Adam()\n",
    "\n",
    "\n",
    "train = True\n",
    "count = 0\n",
    "\n",
    "for (X, y) in dataloader:\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break\n",
    "    print(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
