{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/cifar-10-python.tar.gz to data\n"
     ]
    }
   ],
   "source": [
    "## Data Prep\n",
    "\n",
    "dataset = CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    transform=Compose([ToTensor(), Normalize(0.5, 0.5)]),\n",
    "    download=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1529,  0.1059,  0.2471,  ...,  0.0588,  0.2235,  0.1137],\n",
      "          [-0.2549, -0.1216,  0.0824,  ..., -0.1294,  0.0118,  0.0824],\n",
      "          [-0.2863, -0.2627,  0.0902,  ..., -0.2392, -0.0196,  0.0745],\n",
      "          ...,\n",
      "          [-0.3333, -0.3804, -0.4118,  ..., -0.3020, -0.3020, -0.2627],\n",
      "          [-0.3020, -0.3333, -0.3804,  ..., -0.3725, -0.3490, -0.4118],\n",
      "          [-0.2314, -0.2941, -0.3333,  ..., -0.4980, -0.5216, -0.5529]],\n",
      "\n",
      "         [[-0.3020, -0.0902,  0.0039,  ..., -0.1137,  0.0431,  0.0667],\n",
      "          [-0.3804, -0.2784, -0.0980,  ..., -0.2235, -0.0510,  0.0667],\n",
      "          [-0.3961, -0.3725, -0.0275,  ..., -0.2627, -0.0353,  0.0353],\n",
      "          ...,\n",
      "          [-0.3804, -0.4275, -0.4667,  ..., -0.2549, -0.2471, -0.2000],\n",
      "          [-0.3412, -0.3725, -0.4196,  ..., -0.3020, -0.2627, -0.3176],\n",
      "          [-0.2706, -0.3333, -0.3725,  ..., -0.4039, -0.4196, -0.4431]],\n",
      "\n",
      "         [[-0.5529, -0.3490, -0.2706,  ..., -0.3098, -0.1608, -0.2392],\n",
      "          [-0.6471, -0.5294, -0.3490,  ..., -0.3804, -0.1843, -0.1686],\n",
      "          [-0.6627, -0.6235, -0.2549,  ..., -0.4039, -0.1608, -0.1686],\n",
      "          ...,\n",
      "          [-0.5451, -0.5843, -0.6157,  ..., -0.7569, -0.7569, -0.6471],\n",
      "          [-0.4902, -0.5216, -0.5686,  ..., -0.7647, -0.7647, -0.7569],\n",
      "          [-0.4196, -0.4824, -0.5216,  ..., -0.8353, -0.8902, -0.8667]]],\n",
      "\n",
      "\n",
      "        [[[-0.2784,  0.0980,  0.5137,  ...,  0.8039,  0.5843,  0.5843],\n",
      "          [-0.1765,  0.2000,  0.7020,  ...,  0.7020,  0.4980,  0.4118],\n",
      "          [-0.2549,  0.1216,  0.7804,  ...,  0.7098,  0.6784,  0.4824],\n",
      "          ...,\n",
      "          [-0.5137, -0.5137, -0.5529,  ..., -0.7333, -0.7569, -0.8745],\n",
      "          [-0.5294, -0.5294, -0.5529,  ..., -0.7098, -0.7412, -0.7569],\n",
      "          [-0.5373, -0.5529, -0.5529,  ..., -0.7255, -0.7333, -0.7255]],\n",
      "\n",
      "         [[-0.1922,  0.1529,  0.5451,  ...,  0.8196,  0.6235,  0.6392],\n",
      "          [-0.0902,  0.2706,  0.7569,  ...,  0.7333,  0.5216,  0.4588],\n",
      "          [-0.1451,  0.2000,  0.8431,  ...,  0.7490,  0.6863,  0.5137],\n",
      "          ...,\n",
      "          [-0.4824, -0.5059, -0.5686,  ..., -0.6863, -0.7255, -0.8588],\n",
      "          [-0.4902, -0.5137, -0.5608,  ..., -0.6549, -0.6941, -0.7176],\n",
      "          [-0.4902, -0.5137, -0.5216,  ..., -0.6471, -0.6549, -0.6471]],\n",
      "\n",
      "         [[-0.1843,  0.1765,  0.5765,  ...,  0.7725,  0.4980,  0.4275],\n",
      "          [-0.0588,  0.2941,  0.7804,  ...,  0.6706,  0.4353,  0.3412],\n",
      "          [-0.0902,  0.2392,  0.8588,  ...,  0.6941,  0.6314,  0.4980],\n",
      "          ...,\n",
      "          [-0.3882, -0.4588, -0.5059,  ..., -0.5608, -0.6235, -0.7647],\n",
      "          [-0.3882, -0.4431, -0.4667,  ..., -0.5294, -0.5765, -0.6078],\n",
      "          [-0.3961, -0.4275, -0.4275,  ..., -0.5137, -0.5216, -0.5059]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5765,  0.5608,  0.5843,  ...,  0.8510,  0.8275,  0.7255],\n",
      "          [ 0.6000,  0.5922,  0.6706,  ...,  0.7647,  0.6235,  0.4667],\n",
      "          [ 0.6157,  0.6471,  0.7176,  ...,  0.4745,  0.2706,  0.1843],\n",
      "          ...,\n",
      "          [-0.3647, -0.3725, -0.3804,  ..., -0.3961, -0.4039, -0.4118],\n",
      "          [-0.3647, -0.3647, -0.3490,  ..., -0.3882, -0.3882, -0.3804],\n",
      "          [-0.3647, -0.3804, -0.3804,  ..., -0.3647, -0.3725, -0.3725]],\n",
      "\n",
      "         [[ 0.5294,  0.5451,  0.5843,  ...,  0.8510,  0.8196,  0.7098],\n",
      "          [ 0.5529,  0.5765,  0.6706,  ...,  0.7647,  0.6078,  0.4667],\n",
      "          [ 0.5843,  0.6314,  0.7098,  ...,  0.4745,  0.2706,  0.1922],\n",
      "          ...,\n",
      "          [-0.4588, -0.4588, -0.4667,  ..., -0.4667, -0.4745, -0.4824],\n",
      "          [-0.4588, -0.4510, -0.4353,  ..., -0.4588, -0.4588, -0.4510],\n",
      "          [-0.4510, -0.4667, -0.4667,  ..., -0.4353, -0.4431, -0.4431]],\n",
      "\n",
      "         [[ 0.6078,  0.6078,  0.6392,  ...,  0.8431,  0.8510,  0.7412],\n",
      "          [ 0.6314,  0.6392,  0.7333,  ...,  0.7804,  0.6784,  0.5529],\n",
      "          [ 0.6314,  0.6941,  0.7725,  ...,  0.5529,  0.3490,  0.2784],\n",
      "          ...,\n",
      "          [-0.3176, -0.3412, -0.3647,  ..., -0.4431, -0.4510, -0.4588],\n",
      "          [-0.3176, -0.3333, -0.3255,  ..., -0.4353, -0.4353, -0.4275],\n",
      "          [-0.3412, -0.3569, -0.3569,  ..., -0.4118, -0.4196, -0.4196]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1608, -0.1451, -0.1294,  ...,  0.1216,  0.0745,  0.0431],\n",
      "          [-0.1529, -0.1373, -0.1059,  ...,  0.2000,  0.1137,  0.0353],\n",
      "          [-0.1451, -0.1294, -0.1059,  ...,  0.1686,  0.1216,  0.0510],\n",
      "          ...,\n",
      "          [ 0.1294,  0.1451,  0.2000,  ...,  0.2941,  0.2471,  0.2078],\n",
      "          [-0.1059, -0.0824, -0.0667,  ..., -0.0039, -0.0196, -0.0196],\n",
      "          [-0.2471, -0.2235, -0.2000,  ..., -0.1686, -0.1765, -0.1843]],\n",
      "\n",
      "         [[ 0.0275,  0.0431,  0.0588,  ...,  0.2627,  0.2314,  0.2000],\n",
      "          [ 0.0353,  0.0510,  0.0824,  ...,  0.3255,  0.2706,  0.2000],\n",
      "          [ 0.0431,  0.0588,  0.0824,  ...,  0.3098,  0.2941,  0.2314],\n",
      "          ...,\n",
      "          [-0.0667, -0.0667, -0.0196,  ...,  0.0667,  0.0353, -0.0039],\n",
      "          [-0.2157, -0.2157, -0.2078,  ..., -0.1059, -0.1216, -0.1216],\n",
      "          [-0.2941, -0.2941, -0.2784,  ..., -0.2000, -0.2078, -0.2157]],\n",
      "\n",
      "         [[ 0.3333,  0.3333,  0.3647,  ...,  0.5529,  0.5059,  0.4745],\n",
      "          [ 0.3412,  0.3490,  0.3804,  ...,  0.5608,  0.5294,  0.4824],\n",
      "          [ 0.3412,  0.3569,  0.3804,  ...,  0.5451,  0.5529,  0.5059],\n",
      "          ...,\n",
      "          [-0.2627, -0.2627, -0.2157,  ..., -0.0745, -0.1059, -0.1451],\n",
      "          [-0.2000, -0.1922, -0.1686,  ..., -0.1216, -0.1294, -0.1373],\n",
      "          [-0.1922, -0.1843, -0.1608,  ..., -0.1216, -0.1373, -0.1451]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9843,  0.9608,  0.9686,  ...,  0.9451,  0.9451,  0.9451],\n",
      "          [ 1.0000,  0.9922,  0.9922,  ...,  0.9686,  0.9686,  0.9686],\n",
      "          [ 1.0000,  0.9765,  0.9843,  ...,  0.9608,  0.9608,  0.9529],\n",
      "          ...,\n",
      "          [ 1.0000,  0.9922,  0.9922,  ...,  0.9922,  0.9922,  0.9765],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  0.9922],\n",
      "          [ 1.0000,  0.9765,  0.9843,  ...,  0.9843,  0.9765,  0.9686]],\n",
      "\n",
      "         [[ 0.9843,  0.9608,  0.9686,  ...,  0.9765,  0.9765,  0.9765],\n",
      "          [ 1.0000,  0.9922,  0.9922,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  0.9765,  0.9843,  ...,  0.9843,  0.9843,  0.9843],\n",
      "          ...,\n",
      "          [ 1.0000,  0.9922,  0.9922,  ...,  0.9922,  0.9922,  0.9765],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  0.9765,  0.9843,  ...,  0.9843,  0.9765,  0.9686]],\n",
      "\n",
      "         [[ 0.9843,  0.9608,  0.9686,  ...,  0.9686,  0.9686,  0.9686],\n",
      "          [ 1.0000,  0.9922,  0.9922,  ...,  0.9922,  0.9922,  0.9922],\n",
      "          [ 1.0000,  0.9765,  0.9843,  ...,  0.9843,  0.9843,  0.9765],\n",
      "          ...,\n",
      "          [ 1.0000,  0.9922,  0.9922,  ...,  0.9922,  0.9922,  0.9765],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  0.9922],\n",
      "          [ 1.0000,  0.9765,  0.9843,  ...,  0.9843,  0.9765,  0.9686]]],\n",
      "\n",
      "\n",
      "        [[[-0.4980, -0.4196, -0.3412,  ..., -0.5765, -0.6549, -0.7569],\n",
      "          [-0.5216, -0.5216, -0.5373,  ..., -0.8039, -0.7961, -0.6784],\n",
      "          [-0.6314, -0.6000, -0.5059,  ..., -0.8196, -0.6863, -0.6471],\n",
      "          ...,\n",
      "          [ 0.2941,  0.3333,  0.4039,  ..., -0.2549, -0.3176, -0.0353],\n",
      "          [ 0.3333,  0.4353,  0.4118,  ..., -0.3725, -0.2392, -0.0118],\n",
      "          [ 0.2941,  0.4196,  0.4196,  ..., -0.0824,  0.0902, -0.1451]],\n",
      "\n",
      "         [[-0.3098, -0.1843, -0.1373,  ..., -0.3255, -0.4510, -0.6471],\n",
      "          [-0.3490, -0.3176, -0.3961,  ..., -0.6706, -0.5922, -0.5137],\n",
      "          [-0.4667, -0.4902, -0.4039,  ..., -0.7569, -0.5529, -0.5294],\n",
      "          ...,\n",
      "          [ 0.0745,  0.1216,  0.2000,  ..., -0.3333, -0.4039, -0.1059],\n",
      "          [ 0.1373,  0.2157,  0.1843,  ..., -0.4196, -0.2863, -0.0745],\n",
      "          [ 0.0980,  0.2314,  0.2235,  ..., -0.1294,  0.0431, -0.2000]],\n",
      "\n",
      "         [[-0.5686, -0.5137, -0.4510,  ..., -0.3882, -0.5373, -0.7725],\n",
      "          [-0.5765, -0.5686, -0.5922,  ..., -0.8431, -0.7255, -0.6627],\n",
      "          [-0.5294, -0.6078, -0.5843,  ..., -0.8902, -0.7333, -0.7176],\n",
      "          ...,\n",
      "          [-0.1686, -0.0902, -0.0510,  ..., -0.4196, -0.4824, -0.1922],\n",
      "          [-0.0667,  0.0196, -0.0667,  ..., -0.4667, -0.3333, -0.1686],\n",
      "          [-0.1137,  0.0353, -0.0039,  ..., -0.1922, -0.0275, -0.3098]]]])\n",
      "tensor([5, 1, 0, 1, 5, 6, 8, 8, 4, 9, 7, 5, 0, 5, 7, 9, 9, 3, 9, 7, 9, 4, 1, 7,\n",
      "        1, 5, 8, 3, 9, 0, 0, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 4 is not equal to len(dims) = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m---> 21\u001b[0m     axes[i]\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m     axes[i]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 4 is not equal to len(dims) = 3"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "for (X, y) in dataloader:\n",
    "    print(X)\n",
    "    print(y)\n",
    "    break\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the first five images and their corresponding labels\n",
    "images = []\n",
    "labels = []\n",
    "for i, (image, label) in enumerate(dataloader):\n",
    "    images.append(image)\n",
    "    labels.append(label)\n",
    "    if i == 4:\n",
    "        break\n",
    "\n",
    "# Plot the images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "\n",
    "for i in range(5):\n",
    "    axes[i].imshow(images[i].squeeze().permute(1, 2, 0))\n",
    "    axes[i].set_title(f\"Label: {labels[i]}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_steps' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m timesteps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m80\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[43mnum_steps\u001b[49m) \u001b[38;5;66;03m# {80 ...., 0} for 100 elements\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# SDE dictates smaller step sizes at low noise levels\u001b[39;00m\n\u001b[1;32m      4\u001b[0m sigma_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m80\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_steps' is not defined"
     ]
    }
   ],
   "source": [
    "timesteps = np.linspace(80, 0, num_steps) # {80 ...., 0} for 100 elements\n",
    "\n",
    "# SDE dictates smaller step sizes at low noise levels\n",
    "sigma_max = 80\n",
    "sigma_min = 0.002\n",
    "rho = 7 # raise all elements to 7 while maintaining scale\n",
    "steps = torch.arange(0, num_steps)\n",
    "timesteps = ((sigma_max ** (1/rho)) + (steps / (num_steps - 1)) * (sigma_min ** (1/rho) - sigma_max ** (1/rho))) ** rho #scale from 0, num_steps to 80, 0 following some root of step shape—looks like pixel value/time graph\n",
    "print(timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (99,) (100,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m img_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m28\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m28\u001b[39m\n\u001b[1;32m      4\u001b[0m timesteps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m80\u001b[39m, \u001b[38;5;241m0\u001b[39m, num_steps) \u001b[38;5;66;03m# {80 ...., 0} for 100 elements\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtimesteps\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m)\n\u001b[1;32m      8\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(img_shape) \u001b[38;5;241m*\u001b[39m timesteps[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t_curr, t_next \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(timesteps[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], timesteps[\u001b[38;5;241m1\u001b[39m:]):\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (99,) (100,) "
     ]
    }
   ],
   "source": [
    "#ROUGH FORWARD PASS\n",
    "\n",
    "num_steps = 100\n",
    "img_shape = 28 * 28\n",
    "\n",
    "x = torch.randn(img_shape) * timesteps[0]\n",
    "\n",
    "for t_curr, t_next in zip(timesteps[:-1], timesteps[1:]):\n",
    "    \n",
    "    noise_level = t_next / t_curr\n",
    "    \n",
    "    x = x * noise_level + denoise(x, t_curr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BACKWARD PASS\n",
    "for real_img in data:\n",
    "    sigma = np.uniform(0, 80) # noise level\n",
    "    \n",
    "    noised_image = real_img + sigma * torch.randn_like(real_img)\n",
    "    \n",
    "    denoise_image = denoise(noisy_image, sigma) # must give it a noise level as input so it knows how many times to denoise, etc.\n",
    "    \n",
    "    loss = mse(denoise_image, noise_image)\n",
    "    \n",
    "    #train denoiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issues w above\n",
    "noise_image is now scaled to a potentially large value—can be tricky to train and generally unoptimal to have varying input image sizes\n",
    "scale down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_var = 0.5\n",
    "\n",
    "def denoise(noisy_img, sigma):\n",
    "    noisy_img_var = sigma**2 + data_var**2\n",
    "    scaled_noisy_img = noisy_img / noisy_img_var ** 0.5\n",
    "    return net(scaled_noisy_img, sigma) #optionally, scale sigma to -1 to 1 via log fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicting image vs noise\n",
    "\n",
    "most models forward pass involve predicting noise given a noisy_img and a sigma level—clean img reconstructed by noisy_img - noise\n",
    "\n",
    "dynamically adjust how much of the noisy_img is recycled during training (i.e. c_skip should increase in training) and modify return value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(noisy_img, sigma):\n",
    "    sample_img_var = sigma**2 + data_var**2\n",
    "    scaled_noisy_img = noisy_img / sample_img_var**2\n",
    "    return c_skip * noisy_img + c_out * net(scaled_noisy_img, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# varying loss update sizes\n",
    "due to c_skip, c_out, and other denoising reasons—the gradient updates has varying magnitude based on the current noise level—adjust loss weight some how!\n",
    "# allocating training effort\n",
    "weight could potentially be taken advantage of to train the network specifically on certain noise levels—dedicating network capacity where it ocunts. however this can be performed without scaling the magnitude of the losses simply by sampling noises by sampling noise levels during training with a particular probability disttribution that allocates where needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final soln\n",
    "sigma_data = 0.5 # from transform\n",
    "P_mean = -1.2       # average noise level (logarithmic)\n",
    "P_std = 1.2     # spread of random noise levels\n",
    "\n",
    "def net(scaled_img, scaled_noise):\n",
    "    some_noise = torch.randn_like(scaled_img)\n",
    "    return some_noise # the net outputs noise! subtract noise from the dirty_image to get cleaner!\n",
    "\n",
    "def denoise(noisy_image, sigma):\n",
    "        # Input, output and skip scale\n",
    "        c_in = 1 / torch.sqrt(sigma_data**2 + sigma**2)\n",
    "        c_out = sigma * sigma_data / torch.sqrt(sigma**2 + sigma_data**2)\n",
    "        c_skip = sigma_data**2 / (sigma**2 + sigma_data**2)\n",
    "        c_noise = torch.log(sigma) / 4      # noise label warp\n",
    " \n",
    "        # mix the input and network output to extract the clean image\n",
    "        return c_skip * noisy_image + \\\n",
    "                   c_out  * net(c_in * noisy_image, c_noise)\n",
    "                   \n",
    "# training\n",
    "for clean_image in range(1):\n",
    "    sigma = np.exp(P_mean + P_std * torch.randn([]))\n",
    "    \n",
    "    noisy_image = clean_image + sigma * torch.randn_like(clean_image)\n",
    "    \n",
    "    denoised_image = denoise(noisy_image)\n",
    "    \n",
    "    weight = (sigma**2 + sigma_data**2) / (sigma * sigma_data)**2\n",
    "    loss = weight * (denoised_image - clean_image).square().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
