{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, Normalize, ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Data Prep\n",
    "\n",
    "dataset = MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    transform=Compose([ToTensor(), Normalize(0.5, 0.5)]),\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.0000e+01, 7.5691e+01, 7.1583e+01, 6.7667e+01, 6.3936e+01, 6.0384e+01,\n",
      "        5.7001e+01, 5.3783e+01, 5.0721e+01, 4.7810e+01, 4.5043e+01, 4.2415e+01,\n",
      "        3.9920e+01, 3.7551e+01, 3.5304e+01, 3.3173e+01, 3.1153e+01, 2.9240e+01,\n",
      "        2.7428e+01, 2.5713e+01, 2.4091e+01, 2.2558e+01, 2.1109e+01, 1.9740e+01,\n",
      "        1.8448e+01, 1.7230e+01, 1.6081e+01, 1.4998e+01, 1.3979e+01, 1.3019e+01,\n",
      "        1.2117e+01, 1.1268e+01, 1.0471e+01, 9.7232e+00, 9.0214e+00, 8.3634e+00,\n",
      "        7.7470e+00, 7.1700e+00, 6.6302e+00, 6.1256e+00, 5.6543e+00, 5.2144e+00,\n",
      "        4.8042e+00, 4.4220e+00, 4.0661e+00, 3.7351e+00, 3.4274e+00, 3.1418e+00,\n",
      "        2.8768e+00, 2.6311e+00, 2.4037e+00, 2.1934e+00, 1.9990e+00, 1.8196e+00,\n",
      "        1.6541e+00, 1.5017e+00, 1.3616e+00, 1.2328e+00, 1.1145e+00, 1.0062e+00,\n",
      "        9.0695e-01, 8.1625e-01, 7.3344e-01, 6.5793e-01, 5.8919e-01, 5.2670e-01,\n",
      "        4.6998e-01, 4.1858e-01, 3.7207e-01, 3.3006e-01, 2.9219e-01, 2.5810e-01,\n",
      "        2.2748e-01, 2.0003e-01, 1.7547e-01, 1.5354e-01, 1.3401e-01, 1.1664e-01,\n",
      "        1.0124e-01, 8.7614e-02, 7.5593e-02, 6.5015e-02, 5.5731e-02, 4.7608e-02,\n",
      "        4.0521e-02, 3.4359e-02, 2.9018e-02, 2.4405e-02, 2.0435e-02, 1.7033e-02,\n",
      "        1.4127e-02, 1.1658e-02, 9.5680e-03, 7.8078e-03, 6.3328e-03, 5.1034e-03,\n",
      "        4.0845e-03, 3.2452e-03, 2.5583e-03, 2.0000e-03])\n"
     ]
    }
   ],
   "source": [
    "timesteps = np.linspace(80, 0, num_steps) # {80 ...., 0} for 100 elements\n",
    "\n",
    "# SDE dictates smaller step sizes at low noise levels\n",
    "sigma_max = 80\n",
    "sigma_min = 0.002\n",
    "rho = 7 # raise all elements to 7 while maintaining scale\n",
    "steps = torch.arange(0, num_steps)\n",
    "timesteps = ((sigma_max ** (1/rho)) + (steps / (num_steps - 1)) * (sigma_min ** (1/rho) - sigma_max ** (1/rho))) ** rho #scale from 0, num_steps to 80, 0 following some root of step shape—looks like pixel value/time graph\n",
    "print(timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (99,) (100,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m img_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m28\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m28\u001b[39m\n\u001b[1;32m      4\u001b[0m timesteps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m80\u001b[39m, \u001b[38;5;241m0\u001b[39m, num_steps) \u001b[38;5;66;03m# {80 ...., 0} for 100 elements\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtimesteps\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m)\n\u001b[1;32m      8\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(img_shape) \u001b[38;5;241m*\u001b[39m timesteps[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t_curr, t_next \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(timesteps[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], timesteps[\u001b[38;5;241m1\u001b[39m:]):\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (99,) (100,) "
     ]
    }
   ],
   "source": [
    "#ROUGH FORWARD PASS\n",
    "\n",
    "num_steps = 100\n",
    "img_shape = 28 * 28\n",
    "\n",
    "x = torch.randn(img_shape) * timesteps[0]\n",
    "\n",
    "for t_curr, t_next in zip(timesteps[:-1], timesteps[1:]):\n",
    "    \n",
    "    noise_level = t_next / t_curr\n",
    "    \n",
    "    x = x * noise_level + denoise(x, t_curr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BACKWARD PASS\n",
    "for real_img in data:\n",
    "    sigma = np.uniform(0, 80) # noise level\n",
    "    \n",
    "    noised_image = real_img + sigma * torch.randn_like(real_img)\n",
    "    \n",
    "    denoise_image = denoise(noisy_image, sigma) # must give it a noise level as input so it knows how many times to denoise, etc.\n",
    "    \n",
    "    loss = mse(denoise_image, noise_image)\n",
    "    \n",
    "    #train denoiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issues w above\n",
    "noise_image is now scaled to a potentially large value—can be tricky to train and generally unoptimal to have varying input image sizes\n",
    "scale down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_var = 0.5\n",
    "\n",
    "def denoise(noisy_img, sigma):\n",
    "    noisy_img_var = sigma**2 + data_var**2\n",
    "    scaled_noisy_img = noisy_img / noisy_img_var ** 0.5\n",
    "    return net(scaled_noisy_img, sigma) #optionally, scale sigma to -1 to 1 via log fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicting image vs noise\n",
    "\n",
    "most models forward pass involve predicting noise given a noisy_img and a sigma level—clean img reconstructed by noisy_img - noise\n",
    "\n",
    "dynamically adjust how much of the noisy_img is recycled during training (i.e. c_skip should increase in training) and modify return value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(noisy_img, sigma):\n",
    "    sample_img_var = sigma**2 + data_var**2\n",
    "    scaled_noisy_img = noisy_img / sample_img_var**2\n",
    "    return c_skip * noisy_img + c_out * net(scaled_noisy_img, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# varying loss update sizes\n",
    "due to c_skip, c_out, and other denoising reasons—the gradient updates has varying magnitude based on the current noise level—adjust loss weight some how!\n",
    "# allocating training effort\n",
    "weight could potentially be taken advantage of to train the network specifically on certain noise levels—dedicating network capacity where it ocunts. however this can be performed without scaling the magnitude of the losses simply by sampling noises by sampling noise levels during training with a particular probability disttribution that allocates where needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9747)\n"
     ]
    }
   ],
   "source": [
    "# final soln\n",
    "sigma_data = 0.5 # from transform\n",
    "P_mean = -1.2       # average noise level (logarithmic)\n",
    "P_std = 1.2     # spread of random noise levels\n",
    "\n",
    "def net(scaled_img, scaled_noise):\n",
    "    some_noise = torch.randn_like(scaled_img)\n",
    "    return some_noise # the net outputs noise! subtract noise from the dirty_image to get cleaner!\n",
    "\n",
    "def denoise(noisy_image, sigma):\n",
    "        # Input, output and skip scale\n",
    "        c_in = 1 / torch.sqrt(sigma_data**2 + sigma**2)\n",
    "        c_out = sigma * sigma_data / torch.sqrt(sigma**2 + sigma_data**2)\n",
    "        c_skip = sigma_data**2 / (sigma**2 + sigma_data**2)\n",
    "        c_noise = torch.log(sigma) / 4      # noise label warp\n",
    " \n",
    "        # mix the input and network output to extract the clean image\n",
    "        return c_skip * noisy_image + \\\n",
    "                   c_out  * net(c_in * noisy_image, c_noise)\n",
    "                   \n",
    "# training\n",
    "for clean_image in range(1):\n",
    "    sigma = np.exp(P_mean + P_std * torch.randn([]))\n",
    "    \n",
    "    noisy_image = clean_image + sigma * torch.randn_like(clean_image)\n",
    "    \n",
    "    denoised_image = denoise(noisy_image)\n",
    "    \n",
    "    weight = (sigma**2 + sigma_data**2) / (sigma * sigma_data)**2\n",
    "    loss = weight * (denoised_image - clean_image).square().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
